#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨207ãƒ«ãƒ¼ãƒˆï¼ˆ23ç‰©ä»¶Ã—9ç›®çš„åœ°ï¼‰ã®ãƒãƒƒãƒå‡¦ç† - æ”¹è‰¯ç‰ˆ
ãƒ»é‹è³ƒã®æ­£ç¢ºãªæŠ½å‡ºï¼ˆ1000å††ä»¥ä¸Šå¯¾å¿œï¼‰
ãƒ»å®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸGoogle Maps URLã®è¨˜éŒ²
ãƒ»å…¨ãƒ«ãƒ¼ãƒˆè¨˜éŒ²ã®ä¿æŒ
"""

import sys
import os
import json
import time
from datetime import datetime, timedelta
import pytz
import logging
import re

sys.path.insert(0, '/app/output/japandatascience.com/timeline-mapping/api')

from google_maps_scraper import GoogleMapsScraper
from json_data_loader import JsonDataLoader

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ImprovedGoogleMapsScraper(GoogleMapsScraper):
    """æ”¹è‰¯ç‰ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ - URLãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ä»˜ã"""
    
    def __init__(self):
        super().__init__()
        self.last_accessed_url = None
    
    def scrape_route(self, origin, destination, dest_name, arrival_time):
        """ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰: å®Ÿéš›ã®ã‚¢ã‚¯ã‚»ã‚¹URLã‚’è¨˜éŒ²"""
        try:
            # Place IDã‚’äº‹å‰å–å¾—
            origin_place_id = self.get_place_id(origin, "å‡ºç™ºåœ°")
            dest_place_id = self.get_place_id(destination, dest_name)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãURLã‚’æ§‹ç¯‰
            timestamp = int(arrival_time.timestamp())
            
            # URLãƒ‘ã‚¹éƒ¨åˆ†ï¼ˆè¡¨ç¤ºç”¨ã®åå‰ï¼‰
            from urllib.parse import quote
            url = f"https://www.google.com/maps/dir/{quote(origin)}/{quote(destination)}/"
            
            # Place IDã‚’ä½¿ã£ãŸdataãƒ–ãƒ­ãƒ–ã‚’æ§‹ç¯‰
            if origin_place_id and dest_place_id:
                if origin_place_id.startswith('ChIJ') and dest_place_id.startswith('ChIJ'):
                    # Place IDã‚’dataãƒ–ãƒ­ãƒ–ã«åŸ‹ã‚è¾¼ã‚€
                    origin_blob = f"!1m5!1m1!1s{origin_place_id}"
                    dest_blob = f"!1m5!1m1!1s{dest_place_id}"
                    time_blob = f"!2m3!6e1!7e2!8j{timestamp}"  # !6e1=åˆ°ç€æ™‚åˆ»
                    transit_mode = "!3e3"  # å…¬å…±äº¤é€šæ©Ÿé–¢
                    
                    # dataãƒ–ãƒ­ãƒ–ã‚’çµåˆ
                    url += f"data=!4m14!4m13{origin_blob}{dest_blob}{time_blob}{transit_mode}"
                else:
                    # Place IDãŒãªã„å ´åˆã¯å¾“æ¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    url += f"data=!2m3!6e1!7e2!8j{timestamp}!3e3"
            else:
                # Place IDãŒãªã„å ´åˆã¯å¾“æ¥ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                url += f"data=!2m3!6e1!7e2!8j{timestamp}!3e3"
            
            # å®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹URLã‚’è¨˜éŒ²
            self.last_accessed_url = url
            logger.info(f"ğŸ“ ã‚¢ã‚¯ã‚»ã‚¹URL: {url[:100]}...")
            
            # åŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
            result = super().scrape_route(origin, destination, dest_name, arrival_time)
            
            # ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸURLã‚’çµæœã«è¿½åŠ 
            result['accessed_url'] = self.last_accessed_url
            
            return result
            
        except Exception as e:
            logger.error(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'destination': dest_name,
                'accessed_url': self.last_accessed_url
            }
    
    def _extract_fare(self, text):
        """æ”¹è‰¯ç‰ˆ: 4æ¡ä»¥ä¸Šã®é‹è³ƒã‚‚æ­£ç¢ºã«æŠ½å‡º"""
        # æ–™é‡‘ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã‚‚å¯¾å¿œï¼‰
        fare_patterns = [
            r'Â¥\s*(\d{1,3}(?:,\d{3})*)',  # Â¥1,234å½¢å¼
            r'(\d{1,3}(?:,\d{3})*)\s*å††',  # 1,234å††å½¢å¼
            r'Â¥\s*(\d+)',                  # Â¥1234å½¢å¼
            r'(\d+)\s*å††',                  # 1234å††å½¢å¼
            r'ï¿¥\s*(\d+)',                  # å…¨è§’ï¿¥
            r'(\d+)\s*yen'                 # yenè¡¨è¨˜
        ]
        
        for pattern in fare_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                # ã‚«ãƒ³ãƒã‚’é™¤å»ã—ã¦æ•°å€¤ã«å¤‰æ›
                fare_str = match.group(1).replace(',', '')
                try:
                    fare = int(fare_str)
                    # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆ50å††ã€œ10000å††ã®ç¯„å›²ï¼‰
                    if 50 <= fare <= 10000:
                        return fare
                except ValueError:
                    continue
        
        return None

class RouteBatchProcessorImproved:
    """æ”¹è‰¯ç‰ˆãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼"""
    
    def __init__(self, start_from_property=15):  # 15ç•ªç›®ã®ç‰©ä»¶ã‹ã‚‰é–‹å§‹
        self.data_loader = JsonDataLoader()
        self.progress_file = '/app/output/japandatascience.com/timeline-mapping/data/batch_progress_improved.json'
        self.results_file = '/app/output/japandatascience.com/timeline-mapping/data/routes_batch_improved.json'
        self.final_file = '/app/output/japandatascience.com/timeline-mapping/data/properties.json'
        self.start_from_property = start_from_property
        
    def load_existing_progress(self):
        """æ—¢å­˜ã®é€²æ—ã‚’èª­ã¿è¾¼ã¿ï¼ˆ14ç‰©ä»¶åˆ†ï¼‰"""
        existing_file = '/app/output/japandatascience.com/timeline-mapping/data/batch_progress.json'
        if os.path.exists(existing_file):
            with open(existing_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def save_progress(self, progress):
        """é€²æ—çŠ¶æ³ã‚’ä¿å­˜"""
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)
    
    def process_remaining_routes(self):
        """æ®‹ã‚Šã®ãƒ«ãƒ¼ãƒˆã‚’å‡¦ç†ï¼ˆ15ç‰©ä»¶ç›®ã‹ã‚‰ï¼‰"""
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        properties = self.data_loader.get_all_properties()
        destinations = self.data_loader.get_all_destinations()
        
        if not properties or not destinations:
            logger.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        # æ—¢å­˜ã®é€²æ—ã‚’èª­ã¿è¾¼ã¿
        existing_progress = self.load_existing_progress()
        if existing_progress:
            progress = existing_progress
            logger.info(f"æ—¢å­˜ã®é€²æ—ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(progress['completed_properties'])}ç‰©ä»¶å®Œäº†")
        else:
            progress = {
                'completed_properties': [],
                'last_property_index': 0,
                'total_success': 0,
                'total_failed': 0,
                'routes': []
            }
        
        # åˆ°ç€æ™‚åˆ»è¨­å®šï¼ˆæ˜æ—¥ã®10:00ï¼‰
        jst = pytz.timezone('Asia/Tokyo')
        tomorrow = datetime.now(jst) + timedelta(days=1)
        arrival_time = tomorrow.replace(hour=10, minute=0, second=0, microsecond=0)
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š æ”¹è‰¯ç‰ˆãƒãƒƒãƒå‡¦ç†é–‹å§‹")
        logger.info(f"  ç‰©ä»¶æ•°: {len(properties)}ä»¶")
        logger.info(f"  ç›®çš„åœ°æ•°: {len(destinations)}ä»¶")
        logger.info(f"  ç·ãƒ«ãƒ¼ãƒˆæ•°: {len(properties) * len(destinations)}ä»¶")
        logger.info(f"  é–‹å§‹ä½ç½®: ç‰©ä»¶ {self.start_from_property}/{len(properties)}")
        logger.info(f"  åˆ°ç€æ™‚åˆ»: {arrival_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}")
        logger.info("=" * 60)
        
        # 15ç‰©ä»¶ç›®ã‹ã‚‰å‡¦ç†
        for prop_idx, prop in enumerate(properties[self.start_from_property - 1:], self.start_from_property):
            if prop['name'] in progress['completed_properties']:
                logger.info(f"ç‰©ä»¶ {prop_idx}/{len(properties)}: {prop['name']} - ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå‡¦ç†æ¸ˆã¿ï¼‰")
                continue
            
            logger.info(f"\nğŸ¢ ç‰©ä»¶ {prop_idx}/{len(properties)}: {prop['name']}")
            logger.info(f"   ä½æ‰€: {prop['address']}")
            
            # ã“ã®ç‰©ä»¶ç”¨ã®æ”¹è‰¯ç‰ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ä½œæˆ
            scraper = ImprovedGoogleMapsScraper()
            prop_routes = []
            
            try:
                scraper.setup_driver()
                logger.info("   âœ… WebDriveråˆæœŸåŒ–å®Œäº†")
                
                # å„ç›®çš„åœ°ã¸ã®ãƒ«ãƒ¼ãƒˆã‚’æ¤œç´¢
                for dest_idx, dest in enumerate(destinations, 1):
                    route_num = (prop_idx - 1) * len(destinations) + dest_idx
                    total_routes = len(properties) * len(destinations)
                    
                    print(f"   [{route_num}/{total_routes}] {dest['name']}...", end="", flush=True)
                    start_time = time.time()
                    
                    try:
                        # ãƒ«ãƒ¼ãƒˆæ¤œç´¢å®Ÿè¡Œ
                        result = scraper.scrape_route(
                            prop['address'],
                            dest['address'],
                            dest['name'],
                            arrival_time
                        )
                        
                        elapsed = time.time() - start_time
                        
                        # çµæœã‚’è¨˜éŒ²ï¼ˆã‚¢ã‚¯ã‚»ã‚¹URLã‚’å«ã‚€ï¼‰
                        route_data = {
                            'property_name': prop['name'],
                            'property_address': prop['address'],
                            'destination_name': dest['name'],
                            'destination_address': dest['address'],
                            'success': result.get('success', False),
                            'travel_time': result.get('travel_time'),
                            'route_type': result.get('route_type'),
                            'train_lines': result.get('train_lines', []),
                            'fare': result.get('fare'),
                            'accessed_url': result.get('accessed_url'),  # å®Ÿéš›ã®ã‚¢ã‚¯ã‚»ã‚¹URL
                            'processing_time': elapsed,
                            'timestamp': datetime.now().isoformat()
                        }
                        
                        if result.get('success'):
                            progress['total_success'] += 1
                            fare_str = f"Â¥{result['fare']}" if result.get('fare') else "-"
                            print(f" âœ… {result['travel_time']}åˆ† {fare_str} ({elapsed:.1f}ç§’)")
                        else:
                            progress['total_failed'] += 1
                            route_data['error'] = result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
                            print(f" âŒ {result.get('error', 'ä¸æ˜')} ({elapsed:.1f}ç§’)")
                        
                        prop_routes.append(route_data)
                        progress['routes'].append(route_data)
                        
                    except Exception as e:
                        logger.error(f" âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                        progress['total_failed'] += 1
                        route_data = {
                            'property_name': prop['name'],
                            'destination_name': dest['name'],
                            'success': False,
                            'error': str(e),
                            'processing_time': time.time() - start_time,
                            'timestamp': datetime.now().isoformat()
                        }
                        prop_routes.append(route_data)
                        progress['routes'].append(route_data)
                
                # ç‰©ä»¶å®Œäº†
                progress['completed_properties'].append(prop['name'])
                progress['last_property_index'] = prop_idx
                
                # é€²æ—ä¿å­˜
                self.save_progress(progress)
                
                # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
                success_count = sum(1 for r in prop_routes if r['success'])
                logger.info(f"   ç‰©ä»¶å®Œäº†: æˆåŠŸ {success_count}/{len(destinations)}, å¤±æ•— {len(destinations) - success_count}")
                
            except Exception as e:
                logger.error(f"   ç‰©ä»¶å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                
            finally:
                # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if scraper:
                    scraper.close()
                    logger.info("   WebDriverçµ‚äº†")
                
                # å°‘ã—å¾…æ©Ÿï¼ˆãƒ¡ãƒ¢ãƒªè§£æ”¾ã®ãŸã‚ï¼‰
                time.sleep(2)
        
        # å…¨ä½“ã®ã‚µãƒãƒªãƒ¼
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ ãƒãƒƒãƒå‡¦ç†å®Œäº†")
        logger.info(f"  ç·å‡¦ç†æ•°: {progress['total_success'] + progress['total_failed']}")
        logger.info(f"  æˆåŠŸ: {progress['total_success']}")
        logger.info(f"  å¤±æ•—: {progress['total_failed']}")
        logger.info(f"  æˆåŠŸç‡: {progress['total_success'] / max(1, progress['total_success'] + progress['total_failed']) * 100:.1f}%")
        logger.info("=" * 60)
        
        # æœ€çµ‚JSONã‚’ç”Ÿæˆ
        self.generate_final_json(progress)
        
        return True
    
    def generate_final_json(self, progress):
        """æœ€çµ‚çš„ãªproperties.jsonã‚’ç”Ÿæˆ"""
        logger.info("\nğŸ“„ æœ€çµ‚JSONç”Ÿæˆä¸­...")
        
        # ç‰©ä»¶ã”ã¨ã«ãƒ«ãƒ¼ãƒˆã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        from collections import defaultdict
        routes_by_property = defaultdict(list)
        
        for route in progress['routes']:
            if route['success']:
                routes_by_property[route['property_name']].append(route)
        
        # properties.jsonå½¢å¼ã«å¤‰æ›
        properties_data = []
        
        for prop_name, routes in routes_by_property.items():
            # å…ƒã®ç‰©ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            orig_props = self.data_loader.get_all_properties()
            prop_data = next((p for p in orig_props if p['name'] == prop_name), {})
            
            property_json = {
                'name': prop_name,
                'address': routes[0]['property_address'] if routes else prop_data.get('address', ''),
                'rent': prop_data.get('rent'),
                'area': prop_data.get('area'),
                'routes': []
            }
            
            # ãƒ«ãƒ¼ãƒˆæƒ…å ±ã‚’è¿½åŠ 
            for route in routes:
                route_entry = {
                    'destination': route['destination_name'],
                    'total_time': route['travel_time'],
                    'route_type': route['route_type'],
                    'train_lines': route.get('train_lines', []),
                    'fare': route.get('fare'),
                    'accessed_url': route.get('accessed_url')  # å®Ÿéš›ã®ã‚¢ã‚¯ã‚»ã‚¹URL
                }
                property_json['routes'].append(route_entry)
            
            properties_data.append(property_json)
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output = {'properties': properties_data}
        
        with open(self.final_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… properties.json ç”Ÿæˆå®Œäº†")
        logger.info(f"   ä¿å­˜å…ˆ: {self.final_file}")
        logger.info(f"   ç‰©ä»¶æ•°: {len(properties_data)}")


if __name__ == "__main__":
    processor = RouteBatchProcessorImproved(start_from_property=15)
    success = processor.process_remaining_routes()
    sys.exit(0 if success else 1)