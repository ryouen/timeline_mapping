#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¾åœ¨ã®properties.jsonã®ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’åˆ†æ
"""

import json
from collections import Counter

def analyze_properties_data():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open('/app/output/japandatascience.com/timeline-mapping/data/properties.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print("="*80)
    print("ğŸ“Š properties.json ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ")
    print("="*80)
    
    # åŸºæœ¬çµ±è¨ˆ
    print(f"\nç‰©ä»¶æ•°: {len(data['properties'])}")
    
    # å…¨ãƒ«ãƒ¼ãƒˆã‚’åé›†
    all_routes = []
    for prop in data['properties']:
        for route in prop.get('routes', []):
            route['property_name'] = prop['name']
            all_routes.append(route)
    
    print(f"ç·ãƒ«ãƒ¼ãƒˆæ•°: {len(all_routes)}")
    
    # ç•°å¸¸ãªå¾’æ­©æ™‚é–“ã‚’æ¤œå‡º
    print("\nã€ç•°å¸¸ãªå¾’æ­©æ™‚é–“ï¼ˆ10åˆ†ä»¥ä¸Šï¼‰ã€‘")
    suspicious_walks = []
    for route in all_routes:
        if route.get('total_walk_time', 0) >= 10:
            suspicious_walks.append({
                'property': route['property_name'],
                'destination': route.get('destination_name', route.get('destination')),
                'walk_time': route.get('total_walk_time'),
                'total_time': route.get('total_time')
            })
    
    for walk in sorted(suspicious_walks, key=lambda x: x['walk_time'], reverse=True)[:10]:
        print(f"  {walk['property'][:20]:20} â†’ {walk['destination']:20}: å¾’æ­©{walk['walk_time']}åˆ† (ç·{walk['total_time']}åˆ†)")
    
    # é§…ã®ä½¿ç”¨é »åº¦
    print("\nã€ä½¿ç”¨é§…ã®çµ±è¨ˆã€‘")
    stations = Counter()
    for route in all_routes:
        if 'details' in route and 'station_used' in route['details']:
            stations[route['details']['station_used']] += 1
    
    for station, count in stations.most_common():
        print(f"  {station}: {count}å›")
    
    # è·¯ç·šã®ä½¿ç”¨é »åº¦
    print("\nã€ä½¿ç”¨è·¯ç·šã®çµ±è¨ˆã€‘")
    lines = Counter()
    for route in all_routes:
        if 'details' in route and 'trains' in route['details']:
            for train in route['details']['trains']:
                if 'line' in train:
                    lines[train['line']] += 1
    
    for line, count in lines.most_common():
        print(f"  {line}: {count}å›")
    
    # åŒã˜çµŒè·¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
    print("\nã€é‡è¤‡ã™ã‚‹çµŒè·¯ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆé§…â†’é§…ï¼‰ã€‘")
    train_patterns = Counter()
    for route in all_routes:
        if 'details' in route and 'trains' in route['details']:
            for train in route['details']['trains']:
                if 'from' in train and 'to' in train:
                    pattern = f"{train['from']}â†’{train['to']}"
                    train_patterns[pattern] += 1
    
    print("æœ€é »å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³:")
    for pattern, count in train_patterns.most_common(5):
        print(f"  {pattern}: {count}å›")
    
    # ä¸è‡ªç„¶ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
    print("\nã€ä¸è‡ªç„¶ãªå¯èƒ½æ€§ãŒã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘")
    
    # ç¥ç”°â†’æ—¥æœ¬æ©‹ãŒå¤šã™ãã‚‹å ´åˆ
    kanda_nihonbashi = train_patterns.get('ç¥ç”°â†’æ—¥æœ¬æ©‹', 0)
    if kanda_nihonbashi > len(data['properties']) * 3:  # ç‰©ä»¶æ•°Ã—3ä»¥ä¸Šãªã‚‰ç•°å¸¸
        print(f"  âš ï¸ 'ç¥ç”°â†’æ—¥æœ¬æ©‹'ãŒ{kanda_nihonbashi}å›å‡ºç¾ï¼ˆç‰©ä»¶æ•°ã®{kanda_nihonbashi/len(data['properties']):.1f}å€ï¼‰")
    
    # æ‰€è¦æ™‚é–“ã®åˆ†å¸ƒ
    print("\nã€æ‰€è¦æ™‚é–“ã®åˆ†å¸ƒã€‘")
    time_ranges = {
        '0-10åˆ†': 0,
        '11-20åˆ†': 0,
        '21-30åˆ†': 0,
        '31-45åˆ†': 0,
        '46-60åˆ†': 0,
        '60åˆ†ä»¥ä¸Š': 0
    }
    
    for route in all_routes:
        time = route.get('total_time', 0)
        if time <= 10:
            time_ranges['0-10åˆ†'] += 1
        elif time <= 20:
            time_ranges['11-20åˆ†'] += 1
        elif time <= 30:
            time_ranges['21-30åˆ†'] += 1
        elif time <= 45:
            time_ranges['31-45åˆ†'] += 1
        elif time <= 60:
            time_ranges['46-60åˆ†'] += 1
        else:
            time_ranges['60åˆ†ä»¥ä¸Š'] += 1
    
    for range_name, count in time_ranges.items():
        percentage = (count / len(all_routes)) * 100 if all_routes else 0
        print(f"  {range_name}: {count}ä»¶ ({percentage:.1f}%)")
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢
    print("\nã€ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ã€‘")
    issues = []
    
    # å¾’æ­©æ™‚é–“ãŒç•°å¸¸ã«é•·ã„
    if len(suspicious_walks) > len(all_routes) * 0.1:
        issues.append(f"å¾’æ­©æ™‚é–“ãŒ10åˆ†ä»¥ä¸Šã®ãƒ«ãƒ¼ãƒˆãŒ{len(suspicious_walks)}ä»¶ï¼ˆ{len(suspicious_walks)/len(all_routes)*100:.1f}%ï¼‰")
    
    # åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå¤šã™ãã‚‹
    most_common_pattern = train_patterns.most_common(1)[0] if train_patterns else (None, 0)
    if most_common_pattern[1] > len(all_routes) * 0.3:
        issues.append(f"'{most_common_pattern[0]}'ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå…¨ä½“ã®{most_common_pattern[1]/len(all_routes)*100:.1f}%ã‚’å ã‚ã‚‹")
    
    if issues:
        print("âš ï¸ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("âœ… é‡å¤§ãªå•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
    
    return {
        'total_properties': len(data['properties']),
        'total_routes': len(all_routes),
        'suspicious_walks': len(suspicious_walks),
        'quality_issues': issues
    }

if __name__ == "__main__":
    result = analyze_properties_data()
    
    print("\n" + "="*80)
    print("ğŸ’¡ æ¨å¥¨äº‹é …")
    print("="*80)
    
    if result['suspicious_walks'] > 0:
        print("1. å¾’æ­©æ™‚é–“ãŒç•°å¸¸ã«é•·ã„ãƒ«ãƒ¼ãƒˆã‚’å†å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    
    if result['quality_issues']:
        print("2. ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        print("3. å…¨ãƒ«ãƒ¼ãƒˆã‚’æ–°è¦ã«å–å¾—ã—ç›´ã™ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
    else:
        print("ãƒ‡ãƒ¼ã‚¿å“è³ªã¯æ¦‚ã­è‰¯å¥½ã§ã™")